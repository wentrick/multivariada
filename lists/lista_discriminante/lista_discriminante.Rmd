---
title: "Lista Discriminante"
author: "Davi Wentrick Feijó"
date: "2023-07-17"
output: 
  rmdformats::downcute:
    self_contained: true
    thumbnails: false
    lightbox: true
    gallery: false
    highlight: tango
    toc_depth : 4
  html_document:
    toc: false
    toc_depth: 5
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse,readxl,MASS,klaR,ggplot2,knitr,cowplot,Rchoice,AICcmodavg,questionr,mdscore,nlme,effectsize,DescTools,mda,mvnTest,gclus,mclust,caTools)
```


## 85. Johnson e Wichern - Exercício 11.1.


### a)
Sabemos que a funcao da discriminante pode ser obtida por meio da seguinte formula:

$$
\hat{y} = (\bar x_1 + \bar x_2)^T S_{\text{amostral}}x = \hat a^T x
$$
A questao nos dá:

$$
X_1 = \begin{bmatrix} 3 & 7 \\ 2 & 4 \\ 4 & 7 \\ \end{bmatrix} \ \ \ X_2 = \begin{bmatrix} 6 & 9 \\ 5 & 7 \\ 4 & 8 \\ \end{bmatrix}
$$


$$
\bar x_1 = \begin{bmatrix} 3  \\ 6  \\ \end{bmatrix} \ \ \ \ \ \bar x_2 = \begin{bmatrix} 5  \\ 8  \\ \end{bmatrix}
$$

$$
S_{\text{amostral}} = \begin{bmatrix}
2 & -1 \\
1 & 1 \\
\end{bmatrix}
$$

Com isso chegamos a:

$$
( \begin{bmatrix} 3  \\ 6  \\ \end{bmatrix} -  \begin{bmatrix} 5  \\ 8  \\ \end{bmatrix})^T \begin{bmatrix} 2 & -1 \\ 1 & 1 \\ \end{bmatrix}x = \begin{bmatrix} -2 & 0  \\  \end{bmatrix}x = -2x
$$
### b)

Temos 

$$
x_0 = \begin{bmatrix} 2 & 7  \\  \end{bmatrix}
$$
Para alocar a observacao para uma das populacoes temos que calcular o $\hat m$

$$
\hat m = \frac{1}{2}(\hat y_1 + \hat y_2) = \frac{1}{2}(\hat a\bar x_1 + \hat a\bar x_2) = -8
$$
Vamos alocar $x_0$ para $\pi_1$ se:

$$
\hat y_0 = \begin{bmatrix} 2 & 7  \\  \end{bmatrix}x_0 \geq \hat m = -8
$$
caso contrario ele vai para $\pi_2$

$$
\begin{bmatrix} -2 & 0  \\  \end{bmatrix}x_0 = -4
$$
Como o resultado é maior que -8 alocamos a observacaqo para $\pi_1$

## 86. Johnson e Wichern - Exercício 11.2.

```{r}
x11 = c(90.0,115.5,94.8,91.5,117.0,140.1,138.0,112.8,99.0,123.0,81.0,110.0)
x21 = c(18.4,16.8,21.6,20.8,23.6,19.2,17.6,22.4,20,20.8,22.0,20)
x12 = c(105,82.8,94.8,73.2,114.0,79.2,89.4,96,77.4,63.0,81,93)
x22 = c(19.6,20.8,17.2,20.4,17.6,17.6,16,18.4,16.4,18.8,14,14.8)

dados = data.frame(x11,x21,x12,x22)

summary(dados)
```

### a)

```{r}
#obs de cada populacao
n1 = 12
n2 = 12
```


```{r}
x1_barra = c(mean(x11),mean(x21))

x2_barra = c(mean(x12),mean(x22))
```

```{r echo=FALSE}
cat("Medias de X1",x1_barra)
cat("Medias de X2",x2_barra)
```

```{r}
s1 = cov(dados[,c(1,2)])

s2 = cov(dados[,c(3,4)])
```

```{r echo=FALSE}
cat("Covariancia de X1")
s1
cat("Covariancia de X2")
s2
```



```{r}
s_pooled = ((n1-1)/((n1-1)+(n2-1))) * s1 + ((n1-1)/((n1-1)+(n2-1))) * s2

s_pooled_inv = solve(s_pooled)
```

```{r echo=FALSE}
cat("S amostral")
s_pooled
cat("S amostral invertida")
s_pooled_inv
```

```{r}
a = t((x1_barra - x2_barra)) %*% s_pooled_inv

m = 0.5*(a %*% x1_barra+ a %*% x2_barra)
```

```{r echo=FALSE}
cat("Nosso a")
a
cat("Nosso M")
m
```

### b)

```{r echo=FALSE}
class = rep(c("owner","nonowner"),each=12)
test = rep(m,12)
dados = data.frame(class,test, x1 = c(x11, x12), x2 = c(x21, x22)) 
dados <- dados %>%
  mutate(result = a[1] * x1 + a[2] * x2,
         result_class = ifelse(result >=  test , "owner", "nonowner")) 
dados
```

### c)

```{r echo=FALSE}
matriz = dados %>%
  group_by(class,result_class) %>%
  summarise(freq = n())
matriz
```

```{r echo=FALSE}
cat("A frequencia de erro é:",3/24)
```

### d)

Assumimos que  $\pi_1$ e $\pi_2$ vem de uma distribuicao norma multivariada com matriz de covariancias iguais

## 87. Johnson e Wichern - Exercício 11.4.

### a)

$$
c(2|1) = 50 \ \ \ c(1|2) = 100
$$
$$
\frac{f_1(x)}{f_2(x)} = \frac{c(1|2)}{c(2|1)} \frac{p_2}{p_1} = \frac{100}{50} \frac{0.2}{0.8} = 0.5 
$$

### b)

$$
\frac{f_1(x)}{f_2(x)} = \frac{0.3}{0.5} = 0.6 \geq 0.5
$$

logo alocamos para $\pi_1$



## 88. Johnson e Wichern - Exercício 11.10.

### a) 

```{r}
n1 = 11
n2 = 12

x1_barra = c(-1,-1)

x2_barra = c(2,1)

s_pooled = matrix(c(7.3, -1.1,
                       -1.1, 4.8),byrow=TRUE,ncol =2)

p=2
t2 = (x1_barra - x2_barra) %*% solve(((1/11)+(1/12))*  s_pooled) %*% (x1_barra - x2_barra)

pf(t2,p,n1+n2-p-1,lower.tail = F)
```

### b)

```{r}
x0 = c(0,1)

a = t((x1_barra - x2_barra)) %*% solve(s_pooled) 

y_0 = a %*% x0

m = 0.5*(a %*% x1_barra + a %*% x2_barra)
```

Como -0.53 é maior que -0.25 alocamos essa observacao para $\pi_2$ 


## 89. Johnson e Wichern - Exercício 11.24. - Dados: T11-4-BankruptcyData.dat.

```{r echo=FALSE}
BankruptcyData <- read_excel("BankruptcyData.xlsx")%>%
  mutate(x1 = as.numeric(x1),
         x2 = as.numeric(x2),
         x3 = as.numeric(x3),
         x4 = as.numeric(x4))

```

### a)

```{r echo=FALSE}
#par(mfrow=c(3, 1))
plot(BankruptcyData$x1,BankruptcyData$x2)
plot(BankruptcyData$x1,BankruptcyData$x3)
plot(BankruptcyData$x1,BankruptcyData$x4)
```



### b)

```{r echo=FALSE}
dados_falido = BankruptcyData %>%
  filter(x5 == 1)

dados_ativo = BankruptcyData %>%
  filter(x5 == 0)

x1_barra = c(mean(dados_ativo$x1),mean(dados_ativo$x2))

x2_barra = c(mean(dados_falido$x1),mean(dados_falido$x2))

s1 = round(cov(dados_ativo[,c(1,2)]),5)

s2 = round(cov(dados_falido[,c(1,2)]),5)
```

```{r echo=FALSE}
cat("Vetor de medias dos ativos:",x1_barra)
cat("Vetor de medias dos falidos:",x2_barra)
cat("Covariancia dos ativos")
s1
cat("Covariancia dos falidos")
s2
```

### c)

```{r}
dados <- BankruptcyData
gqda <- qda(x5~x1+x2, data = dados,prior =c(.5,.5))

gqdap1 <- predict(gqda)
gqctable1 <- table(dados$x5, gqdap1$class)

# Com validação cruzada
gqdaVC <- qda(x5~x1+x2, data = dados,prior =c(.5,.5),CV=T)
```

```{r echo=FALSE}
cat("Matriz de confusao")
gqctable1
cat("Acerto de classificacao por grupo",(diag(prop.table(gqctable1,1))))
cat("Porporcao total de acerto",(sum(diag(prop.table(gqctable1)))))
```

### d)

```{r}
# Matrizes de confusão:
M <- table(dados$x5, gqdap1$class) 
MCV <- table(dados$x5, gqdaVC$class) 

# APER e \hat{E}APR:
APER <- (sum(M)-sum(diag(M)))/sum(M) # APER x_1,x_2
E_APR <- (sum(MCV)-sum(diag(MCV)))/sum(MCV) # \hat{E} APR x_1,x_2
```

```{r echo=FALSE}
cat("erro aparente (APER) deste conjunto foi:",APER)
cat("estimação da taxa de erro aparente foi:",E_APR)
```


### e)

```{r}
#dados <- dados[,-6]
gqda <- qda(x5~x1+x2, data = dados,prior =c(.05,.95))

gqdap1 <- predict(gqda)
gqctable1 <- table(dados$x5, gqdap1$class)

# Com validação cruzada
gqdaVC <- qda(x5~x1+x2, data = dados,prior =c(.05,.95),CV=T)

# Matrizes de confusão:
M <- table(dados$x5, gqdap1$class) 
MCV <- table(dados$x5, gqdaVC$class) 

# APER e \hat{E}APR:
APER <- (sum(M)-sum(diag(M)))/sum(M) # APER x_1,x_2
E_APR <- (sum(MCV)-sum(diag(MCV)))/sum(MCV) # \hat{E} APR x_1,x_2
```

```{r echo=FALSE}
cat("Matriz de confusao")
gqctable1
cat("Acerto de classificacao por grupo",(diag(prop.table(gqctable1,1))))
cat("Porporcao total de acerto",(sum(diag(prop.table(gqctable1)))))
cat("erro aparente (APER) deste conjunto foi:",APER)
cat("estimação da taxa de erro aparente foi:",E_APR)
```


### f)

```{r}
cov_pooled_inv = solve(cov_pooled(dados_ativo[,c(1,2)],dados_falido[,c(1,2)]))

a <- t(x1_barra - x2_barra) %*% cov_pooled_inv
m <- 0.5*(a %*% x1_barra+ a %*% x2_barra)

pop <- BankruptcyData %>%
  rowwise() %>%
  mutate(M = a %*% c(x1, x2)) %>%
  mutate(pop = ifelse(M > m,0,1)) 
  
matriz = pop %>%
  group_by(x5,pop) %>%
  summarise(freq = n())
matriz

```

```{r echo=FALSE}
cat("erro aparente (APER) deste conjunto foi:",9/46)
```

### g)

#### Analise com $X_1$ e $X_3$
```{r echo=FALSE}
# x1,x3

x1_barra = c(mean(dados_ativo$x1),mean(dados_ativo$x3))

x2_barra = c(mean(dados_falido$x1),mean(dados_falido$x3))

s1 = round(cov(dados_ativo[,c(1,3)]),5)

s2 = round(cov(dados_falido[,c(1,3)]),5)
```

```{r echo=FALSE}
cat("Vetor de medias dos ativos:",x1_barra)
cat("Vetor de medias dos falidos:",x2_barra)
cat("Covariancia dos ativos")
s1
cat("Covariancia dos falidos")
s2
```

Usando a priori $0.5|0.5$
```{r echo=FALSE}
#analise com 0.5\0.5

#dados <- dados[,-6]
gqda <- qda(x5~x1+x3, data = dados,prior =c(.5,.5))

gqdap1 <- predict(gqda)
gqctable1 <- table(dados$x5, gqdap1$class)

# Com validação cruzada
gqdaVC <- qda(x5~x1+x3, data = dados,prior =c(.5,.5),CV=T)

# Matrizes de confusão:
M <- table(dados$x5, gqdap1$class) 
MCV <- table(dados$x5, gqdaVC$class) 

# APER e \hat{E}APR:
APER <- (sum(M)-sum(diag(M)))/sum(M) # APER x_1,x_2
E_APR <- (sum(MCV)-sum(diag(MCV)))/sum(MCV) # \hat{E} APR x_1,x_2
```

```{r echo=FALSE}
cat("Matriz de confusao")
gqctable1
cat("Acerto de classificacao por grupo",(diag(prop.table(gqctable1,1))))
cat("Porporcao total de acerto",(sum(diag(prop.table(gqctable1)))))
cat("erro aparente (APER) deste conjunto foi:",APER)
cat("estimação da taxa de erro aparente foi:",E_APR)
```

Usando a priori $0.05|0.95$
```{r echo=FALSE}
#analise com 0.05\0.95

#dados <- dados[,-6]
gqda <- qda(x5~x1+x3, data = dados,prior =c(.05,.95))

gqdap1 <- predict(gqda)
gqctable1 <- table(dados$x5, gqdap1$class)

# Com validação cruzada
gqdaVC <- qda(x5~x1+x3, data = dados,prior =c(.05,.95),CV=T)

# Matrizes de confusão:
M <- table(dados$x5, gqdap1$class) 
MCV <- table(dados$x5, gqdaVC$class) 

# APER e \hat{E}APR:
APER <- (sum(M)-sum(diag(M)))/sum(M) # APER x_1,x_2
E_APR <- (sum(MCV)-sum(diag(MCV)))/sum(MCV) # \hat{E} APR x_1,x_2
```

```{r echo=FALSE}
cat("Matriz de confusao")
gqctable1
cat("Acerto de classificacao por grupo",(diag(prop.table(gqctable1,1))))
cat("Porporcao total de acerto",(sum(diag(prop.table(gqctable1)))))
cat("erro aparente (APER) deste conjunto foi:",APER)
cat("estimação da taxa de erro aparente foi:",E_APR)
```

#### Analise com $X_1$ e $X_4$
```{r echo=FALSE}
# x1,x4

x1_barra = c(mean(dados_ativo$x1),mean(dados_ativo$x4))

x2_barra = c(mean(dados_falido$x1),mean(dados_falido$x4))

s1 = round(cov(dados_ativo[,c(1,4)]),5)

s2 = round(cov(dados_falido[,c(1,4)]),5)
```

```{r echo=FALSE}
cat("Vetor de medias dos ativos:",x1_barra)
cat("Vetor de medias dos falidos:",x2_barra)
cat("Covariancia dos ativos")
s1
cat("Covariancia dos falidos")
s2
```

```{r echo=FALSE}
#analise com 0.5\0.5

#dados <- dados[,-6]
gqda <- qda(x5~x1+x4, data = dados,prior =c(.5,.5))

gqdap1 <- predict(gqda)
gqctable1 <- table(dados$x5, gqdap1$class)

# Com validação cruzada
gqdaVC <- qda(x5~x1+x4, data = dados,prior =c(.5,.5),CV=T)

# Matrizes de confusão:
M <- table(dados$x5, gqdap1$class) 
MCV <- table(dados$x5, gqdaVC$class) 

# APER e \hat{E}APR:
APER <- (sum(M)-sum(diag(M)))/sum(M) # APER x_1,x_2
E_APR <- (sum(MCV)-sum(diag(MCV)))/sum(MCV) # \hat{E} APR x_1,x_2
```

```{r echo=FALSE}
cat("Matriz de confusao")
gqctable1
cat("Acerto de classificacao por grupo",(diag(prop.table(gqctable1,1))))
cat("Porporcao total de acerto",(sum(diag(prop.table(gqctable1)))))
cat("erro aparente (APER) deste conjunto foi:",APER)
cat("estimação da taxa de erro aparente foi:",E_APR)
```


```{r echo=FALSE}
#analise com 0.05\0.95

#dados <- dados[,-6]
gqda <- qda(x5~x1+x4, data = dados,prior =c(.05,.95))

gqdap1 <- predict(gqda)
gqctable1 <- table(dados$x5, gqdap1$class)

# Com validação cruzada
gqdaVC <- qda(x5~x1+x4, data = dados,prior =c(.05,.95),CV=T)

# Matrizes de confusão:
M <- table(dados$x5, gqdap1$class) 
MCV <- table(dados$x5, gqdaVC$class) 

# APER e \hat{E}APR:
APER <- (sum(M)-sum(diag(M)))/sum(M) # APER x_1,x_2
E_APR <- (sum(MCV)-sum(diag(MCV)))/sum(MCV) # \hat{E} APR x_1,x_2
```

```{r echo=FALSE}
cat("Matriz de confusao")
gqctable1
cat("Acerto de classificacao por grupo",(diag(prop.table(gqctable1,1))))
cat("Porporcao total de acerto",(sum(diag(prop.table(gqctable1)))))
cat("erro aparente (APER) deste conjunto foi:",APER)
cat("estimação da taxa de erro aparente foi:",E_APR)
```


### h)

```{r echo=FALSE}
# x1,x4

x1_barra = c(mean(dados_ativo$x1),mean(dados_ativo$x4))

x2_barra = c(mean(dados_falido$x1),mean(dados_falido$x4))

s1 = round(cov(dados_ativo[,c(1:4)]),5)

s2 = round(cov(dados_falido[,c(1:4)]),5)
```

```{r echo=FALSE}
cat("Vetor de medias dos ativos:",x1_barra)
cat("Vetor de medias dos falidos:",x2_barra)
cat("Covariancia dos ativos")
s1
cat("Covariancia dos falidos")
s2
```

Usando a priori $0.5|0.5$
```{r echo=FALSE}
#analise com 0.5\0.5

#dados <- dados[,-6]
gqda <- qda(x5~x1+x2+x3+x4, data = dados,prior =c(.5,.5))

gqdap1 <- predict(gqda)
gqctable1 <- table(dados$x5, gqdap1$class)

# Com validação cruzada
gqdaVC <- qda(x5~x1+x2+x3+x4, data = dados,prior =c(.5,.5),CV=T)

# Matrizes de confusão:
M <- table(dados$x5, gqdap1$class) 
MCV <- table(dados$x5, gqdaVC$class) 

# APER e \hat{E}APR:
APER <- (sum(M)-sum(diag(M)))/sum(M) # APER x_1,x_2
E_APR <- (sum(MCV)-sum(diag(MCV)))/sum(MCV) # \hat{E} APR x_1,x_2
```

```{r echo=FALSE}
cat("Matriz de confusao")
gqctable1
cat("Acerto de classificacao por grupo",(diag(prop.table(gqctable1,1))))
cat("Porporcao total de acerto",(sum(diag(prop.table(gqctable1)))))
cat("erro aparente (APER) deste conjunto foi:",APER)
cat("estimação da taxa de erro aparente foi:",E_APR)
```

Usando a priori $0.05|0.95$
```{r echo=FALSE}
#analise com 0.05\0.95

#dados <- dados[,-6]
gqda <- qda(x5~x1+x2+x3+x4, data = dados,prior =c(.05,.95))

gqdap1 <- predict(gqda)
gqctable1 <- table(dados$x5, gqdap1$class)

# Com validação cruzada
gqdaVC <- qda(x5~x1+x2+x3+x4, data = dados,prior =c(.05,.95),CV=T)

# Matrizes de confusão:
M <- table(dados$x5, gqdap1$class) 
MCV <- table(dados$x5, gqdaVC$class) 

# APER e \hat{E}APR:
APER <- (sum(M)-sum(diag(M)))/sum(M) # APER x_1,x_2
E_APR <- (sum(MCV)-sum(diag(MCV)))/sum(MCV) # \hat{E} APR x_1,x_2
```

```{r echo=FALSE}
cat("Matriz de confusao")
gqctable1
cat("Acerto de classificacao por grupo",(diag(prop.table(gqctable1,1))))
cat("Porporcao total de acerto",(sum(diag(prop.table(gqctable1)))))
cat("erro aparente (APER) deste conjunto foi:",APER)
cat("estimação da taxa de erro aparente foi:",E_APR)
```


## 90. Johnson e Wichern - Exercício 11.32. - Dados: T11-8-Hemofilia.dat.

```{r}
Hemofilia <- read_excel("Hemofilia.xlsx") %>%
  mutate(x1 = as.factor(x1),
         x2 = as.numeric(x2),
         x3 = as.numeric(x3))
```


### a)
```{r}
plot(Hemofilia$x2,Hemofilia$x3, col=Hemofilia$x1)
```

### b)

```{r echo=FALSE}
hemo_1 = Hemofilia %>%
  filter(x1 == 1)

hemo_2 = Hemofilia %>%
  filter(x1 == 2)

x1_barra = c(mean(hemo_1$x2),mean(hemo_1$x3))

x2_barra = c(mean(hemo_2$x2),mean(hemo_2$x3))

s1 = cov(hemo_1[,c(2,3)])

s2 = cov(hemo_2[,c(2,3)])
```

```{r echo=FALSE}
cat("Vetor de medias do grupo 1:",x1_barra)
cat("Vetor de medias dos grupo 2:",x2_barra)
cat("Covariancia do grupo 1")
s1
cat("Covariancia do grupo 2")
s2
```

```{r echo=FALSE}
#analise com 0.05\0.95

#dados <- dados[,-6]
glda <- lda(x1~x2+x3, data = Hemofilia,prior =c(.5,.5))

gldp1 <- predict(glda)
glctable1 <- table(Hemofilia$x1, gldp1$class)

# Com validação cruzada
gldaVC <- lda(x1~x2+x3, data = Hemofilia,prior =c(.5,.5),CV=T)

# Matrizes de confusão:
M <- table(Hemofilia$x1, gldp1$class) 
MCV <- table(Hemofilia$x1, gldaVC$class) 

# APER e \hat{E}APR:
APER <- (sum(M)-sum(diag(M)))/sum(M) # APER x_1,x_2
E_APR <- (sum(MCV)-sum(diag(MCV)))/sum(MCV) # \hat{E} APR x_1,x_2
```

Validacao Holdout

```{r}
set.seed(123)
split <- sample.split(Hemofilia$x1, SplitRatio = 0.5) 
train <- subset(Hemofilia, split==T)
test <- subset(Hemofilia, split==F)

lda_train <- lda(x1~x2+x3, data = train,prior =c(.5,.5))

PT <- predict(lda_train, newdata = test, type = "response")
glctable <- table(test$x1, PT$x >= 0.5)
```

```{r echo=FALSE}
cat("Matriz de confusao")
glctable
cat("Acerto de classificacao por grupo",(diag(prop.table(glctable,1))))
cat("Porporcao total de acerto",(sum(diag(prop.table(glctable)))))
cat("erro aparente (APER) deste conjunto foi:",APER)
cat("estimação da taxa de erro aparente foi:",E_APR)
```
### c)

```{r}
df <- read_table("tabela12.32c.txt", 
                    col_names = FALSE)
colnames(df) <- c("x2","x3")
df$X1 <- NA
```


```{r}
pred = predict(lda_train, newdata = df, type = "response")
pred
```
Todas as observacoes foram para o grupo 1 

### D)

```{r echo=FALSE}
#analise com 0.05\0.95

#dados <- dados[,-6]
glda <- lda(x1~x2+x3, data = Hemofilia,prior =c(.75,.25))

gldp1 <- predict(glda)
glctable1 <- table(Hemofilia$x1, gldp1$class)

# Com validação cruzada
gldaVC <- lda(x1~x2+x3, data = Hemofilia,prior =c(.75,.25),CV=T)

# Matrizes de confusão:
M <- table(Hemofilia$x1, gldp1$class) 
MCV <- table(Hemofilia$x1, gldaVC$class) 

# APER e \hat{E}APR:
APER <- (sum(M)-sum(diag(M)))/sum(M) # APER x_1,x_2
E_APR <- (sum(MCV)-sum(diag(MCV)))/sum(MCV) # \hat{E} APR x_1,x_2
```

Validacao Holdout

```{r}
set.seed(123)
split <- sample.split(Hemofilia$x1, SplitRatio = 0.5) 
train <- subset(Hemofilia, split==T)
test <- subset(Hemofilia, split==F)

lda_train <- lda(x1~x2+x3, data = train,prior =c(.75,.25))

PT <- predict(lda_train, newdata = test, type = "response")
glctable <- table(test$x1, PT$x >= 0.75)
```

```{r echo=FALSE}
cat("Matriz de confusao")
glctable
cat("Acerto de classificacao por grupo",(diag(prop.table(glctable,1))))
cat("Porporcao total de acerto",(sum(diag(prop.table(glctable)))))
cat("erro aparente (APER) deste conjunto foi:",APER)
cat("estimação da taxa de erro aparente foi:",E_APR)
```

```{r}
pred = predict(lda_train, newdata = df, type = "response")
pred
```


## 91. Considere os dados sobre falsificação de notas do Exercício 84. Realize as análises Linear e Quadrática de discriminantes. É possível utilizar mistura de normais (função `mclust`) como análise de discriminantes? Se sim, faça o estudo e compare as estimativas APER para as três situações. Resuma os resultados e conclusões.

```{r}
# Discriminante linear
data(bank)
bank$Status <- factor(bank$Status)

LDA <- lda(Status~., data = bank,prior=c(.5,.5))
LDAp1 <- predict(LDA)
LDAtable1 <- table(bank$Status, LDAp1$class)
prop1 <- (diag(prop.table(LDAtable1,1))) # prop de classif. correta no grupo
propt1 <- (sum(diag(prop.table(LDAtable1)))) # prop total de classf. correta 

# Matrizes de confusão:
M <- table(bank$Status, LDAp1$class) 

# APER:
APER <- (sum(M)-sum(diag(M)))/sum(M)

#partimat(Status ~ ., data = bank, method = "lda")

# Discriminante quadrático
QDA <- qda(Status~., data = bank,prior=c(.5,.5))
QDAp1 <- predict(QDA)
QDAtable1 <- table(bank$Status, QDAp1$class)
prop2 <- (diag(prop.table(QDAtable1,1))) # prop de classif. correta no grupo
propt2 <- (sum(diag(prop.table(QDAtable1)))) # prop total de classf. correta 

# Matrizes de confusão:
M1 <- table(bank$Status, QDAp1$class) 

# APER:
APER1 <- (sum(M1)-sum(diag(M1)))/sum(M1)

#partimat(Status ~ ., data = bank, method = "qda")

# Análise de discriminantes por mistura de normais (mclust)

Class <- factor(bank$Status, levels = 0:1,
                labels = c("Genuína", "Falsificada"))

X <- data.matrix(bank[,-1])

mod <- Mclust(X)
summary(mod$BIC)

plot(mclustBIC(X))

summary(mod)
table(Class, mod$classification)    # por algum motivo este não renderiza
RAND <- adjustedRandIndex(Class, mod$classification)

# Matrizes de confusão:
M2 <- table(bank$Status, mod$class) 

# APER:
APER2 <- (2+16)/(2+98+16+84)
```







